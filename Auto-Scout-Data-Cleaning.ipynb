{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bkw3_pB0s1L-"
   },
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" \n",
    "alt=\"CLRSWY\"></p>\n",
    "\n",
    "## <p style=\"background-color:#FDFEFE; font-family:newtimeroman; color:#9d4f8c; font-size:100%; text-align:center; border-radius:10px 10px;\">WAY TO REINVENT YOURSELF</p>\n",
    "\n",
    "## <p style=\"background-color:#FDFEFE; font-family:newtimeroman; color:#060108; font-size:200%; text-align:center; border-radius:10px 10px;\">DA & DVwPY</p>\n",
    "\n",
    "## <p style=\"background-color:#FDFEFE; font-family:newtimeroman; color:#060108; font-size:200%; text-align:center; border-radius:10px 10px;\">The Exploratory Data Analysis (EDA) Project</p>\n",
    "\n",
    "<img src=https://i.ibb.co/wJW61Y2/Used-cars.jpg width=\"700\" height=\"200\">\n",
    "\n",
    "## <p style=\"background-color:#FDFEFE; font-family:newtimeroman; color:#060108; font-size:200%; text-align:center; border-radius:10px 10px;\">AutoScout Car Price Prediction EDA</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_oWczxZs1MA"
   },
   "source": [
    "## Introduction\n",
    "Welcome to \"***AutoScout Exploratory Data Analysis (EDA) Project***\". This is the project of completing ***Data Analysis & Data Visualization*** Courses and a successful hand-over is mandatory for getting certification for both courses. **Auto Scout** data used in this project scraped from the Website of an online car trading company in 2022, and contains many features of 13 different car makes including 594 models. In this project, you will have the opportunity to apply many commonly used algorithms for Data Cleaning and Exploratory Data Analysis by using a variety of Python libraries, such as Numpy, Pandas, Matplotlib, Seaborn, Scipy, and then you will get a clean dataset for your analysis and pretictive modelling in Machine Learning Path. So you will have the chance to use all the skills you have already learned in the Data Analysis and Visualization courses.\n",
    "\n",
    "**``In this context, the project consists of 3 parts in general:``**\n",
    "* **The first part** is related to ``'Data Cleaning'``. It deals with Incorrect Headers, Incorrect Format, Anomalies, and Dropping useless columns.\n",
    "* **The second part** is related to ``'Filling Data'``, in other words 'Imputation'. It deals with Missing Values. Categorical to numeric transformation, Encoding, is done as well.\n",
    "* **The third part** is related to ``'Handling Outliers of Data'`` via Visualization libraries. So, some insights will be extracted.\n",
    "\n",
    "**``SPECIAL NOTE:``**  However, you are ``free to create your own style``. You do ``NOT`` have to stick to the steps above. Nevertheless, we, the DA & DV instructors, recommend you study each part separately to create a source notebook for your further studies. \n",
    "\n",
    "In order to build your Portfolio in terms of the GitHub account, you need to push your solution file up to your own repository.\n",
    "\n",
    "Please after solving the task, commit your notebook to GitHub and submit its link to LMS page where the project is settled down.\n",
    "\n",
    "**BE NOTED:** Please ``DO NOT FORGET`` to click the submit button.\n",
    "\n",
    "### Some Reminders on Exploratory data analysis (EDA)\n",
    "\n",
    "Exploratory data analysis (EDA) is an especially important activity in the routine of a data analyst or scientist. It enables an in depth understanding of the dataset, define or discard hypotheses and create predictive models on a solid basis. It uses data manipulation techniques and several statistical tools to describe and understand the relationship between variables and how these can impact business. By means of EDA, we can obtain meaningful insights that can impact analysis under the following questions (If a checklist is good enough for pilots to use every flight, it’s good enough for data scientists to use with every dataset).\n",
    "1. What question are you trying to solve (or prove wrong)?\n",
    "2. What kind of data do you have?\n",
    "3. What’s missing from the data?\n",
    "4. Where are the outliers?\n",
    "5. How can you add, change or remove features to get more out of your data?\n",
    "\n",
    "**``Exploratory data analysis (EDA)``** is often an **iterative brainstorming process** where you pose a question, review the data, and develop further questions to investigate before beginning model development work. The image below shows how the brainstorming phase is connected with that of understanding the variables and how this in turn is connected again with the brainstorming phase.<br>\n",
    "\n",
    "<img src=https://i.ibb.co/k0MC950/EDA-Process.png width=\"300\" height=\"100\">\n",
    "\n",
    "[Image Credit: Andrew D.](https://towardsdatascience.com/exploratory-data-analysis-in-python-a-step-by-step-process-d0dfa6bf94ee)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import regex as re\n",
    "pd.options.display.max_colwidth = 20\n",
    "pd.options.display.max_columns = None\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.warn(\"this will not show\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def def_show_nulls(data):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    This function plots missing values for each column by observation in the dataset.\n",
    "    \n",
    "    ''' \n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    sns.displot(data=data.isnull().melt(value_name=\"missing\"),\n",
    "                y=\"variable\",\n",
    "                hue=\"missing\",\n",
    "                multiple=\"fill\",\n",
    "                height=9.25)\n",
    "\n",
    "    plt.axvline(0.2, color=\"r\")\n",
    "    plt.show()\n",
    "    \n",
    "# ---------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def def_col_name(x):\n",
    "    '''\n",
    "    \n",
    "    This function is made to change incompatible column names.\n",
    "    \n",
    "    '''\n",
    "    col_dict = {}\n",
    "    for col in x.columns:\n",
    "        new_col = col.strip().replace(' & ','_').replace(' ','_').replace('-','_').replace('CO₂','co2').replace('(','').replace(')','').lower()\n",
    "        col_dict[col]= new_col\n",
    "        x.rename(columns=col_dict, inplace=True)\n",
    "        \n",
    "# ---------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def def_col_val_analysis(x):\n",
    "    '''\n",
    "    \n",
    "    This function was created to help you figure out what type of data is in the column as \n",
    "    it performs operations on each column.\n",
    "    \n",
    "    '''\n",
    "    for col in x.columns:\n",
    "        t_list = []\n",
    "        for val in x[col]:\n",
    "            t_list.append(type(val))\n",
    "        print(pd.Series(t_list).value_counts())\n",
    "        print(col+'\\n')\n",
    "        \n",
    "# ---------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def def_clean_column(x):\n",
    "    for i in range(0,len(x)):\n",
    "        if x[i] != 'Unknown':\n",
    "            x[i] = x[i][0].replace(',','').strip()\n",
    "            \n",
    "# ---------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def def_clean_column1(x):\n",
    "    for i in range(len(x)):\n",
    "        if x[i] != 'Unknown':\n",
    "            x[i] = x[i][0].strip().replace(',','')\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def assign_consumption_value(df, i, idx, consumption_type):\n",
    "    num = df.fuel_consumption[i][idx][0].split()[0]\n",
    "    if consumption_type == '(city)':\n",
    "        df.consumption_city[i] = num\n",
    "    elif consumption_type == '(country)':\n",
    "        df.consumption_country[i] = num\n",
    "    elif consumption_type == '(comb.)':\n",
    "        df.consumption_comb[i] = num\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------------#\n",
    "        \n",
    "def def_fill_miss(data, col_num, agg_func, col_target, first_col, second_col=None, third_col=None):\n",
    "    '''\n",
    "    \n",
    "    This function is created to fill in missing data according to similar properties of other columns.\n",
    "    \n",
    "    '''\n",
    "    indexes = data[data[col_target].isnull()==True].index\n",
    "    \n",
    "    if agg_func == 'mean':\n",
    "        if col_num == 1:\n",
    "            for i in indexes:\n",
    "                data[col_target][i] = data[data[first_col]==data[first_col][i]][col_target].mean()\n",
    "                if isinstance(data[col_target][i], float) and np.isnan(data[col_target][i]):\n",
    "                    data[col_target][i] = data[col_target].mean()\n",
    "        elif col_num == 2:\n",
    "            for i in indexes:\n",
    "                data[col_target][i] = data[(data[first_col]==data[first_col][i]) & (data[second_col]==data[second_col][i])][col_target].mean()\n",
    "                if isinstance(data[col_target][i], float) and np.isnan(data[col_target][i]):\n",
    "                    data[col_target][i] = data[data[first_col]==data[first_col][i]][col_target].mean()\n",
    "                    if isinstance(data[col_target][i], float) and np.isnan(data[col_target][i]):\n",
    "                        data[col_target][i] = data[col_target].mean()\n",
    "        elif col_num == 3:\n",
    "            for i in indexes:\n",
    "                data[col_target][i] = data[(data[first_col]==data[first_col][i]) & (data[second_col]==data[second_col][i]) & (data[third_col]==data[third_col][i])][col_target].mean()\n",
    "                if isinstance(data[col_target][i], float) and np.isnan(data[col_target][i]):\n",
    "                    data[col_target][i] = data[(data[first_col]==data[first_col][i]) & (data[second_col]==data[second_col][i])][col_target].mean()    \n",
    "                    if isinstance(data[col_target][i], float) and np.isnan(data[col_target][i]):\n",
    "                        data[col_target][i] = data[data[first_col]==data[first_col][i]][col_target].mean()\n",
    "                        if isinstance(data[col_target][i], float) and np.isnan(data[col_target][i]):\n",
    "                            data[col_target][i] = data[col_target].mean()\n",
    "                    \n",
    "    elif agg_func == 'mode':\n",
    "        if col_num == 1: \n",
    "            for i in indexes:\n",
    "                a = data[data[first_col]==data[first_col][i]][col_target].mode()\n",
    "                if len(a) > 0:\n",
    "                    data[col_target][i] = a[0]\n",
    "                else:\n",
    "                    data[col_target][i] = data[col_target].mode()[0]\n",
    "        elif col_num == 2:\n",
    "            for i in indexes:\n",
    "                a = data[(data[first_col]==data[first_col][i]) & (data[second_col]==data[second_col][i])][col_target].mode()\n",
    "                if len(a) > 0:\n",
    "                    data[col_target][i] = a[0]\n",
    "                else:\n",
    "                    aa = data[data[first_col]==data[first_col][i]][col_target].mode()\n",
    "                    if len(aa) > 0:\n",
    "                        data[col_target][i] = aa[0]\n",
    "                    else:\n",
    "                        data[col_target][i] = data[col_target].mode()[0]\n",
    "        elif col_num == 3:\n",
    "            for i in indexes:\n",
    "                a = data[(data[first_col]==data[first_col][i]) & (data[second_col]==data[second_col][i]) & (data[third_col]==data[third_col][i])][col_target].mode()\n",
    "                if len(a) > 0:\n",
    "                    data[col_target][i] = a[0]\n",
    "                else:\n",
    "                    aa = data[(data[first_col]==data[first_col][i]) & (data[second_col]==data[second_col][i])][col_target].mode()\n",
    "                    if len(aa) > 0:\n",
    "                        data[col_target][i] = aa[0]\n",
    "                    else:\n",
    "                        aaa = data[data[first_col]==data[first_col][i]][col_target].mode()\n",
    "                        if len(aaa) > 0:\n",
    "                            data[col_target][i] = aaa[0]\n",
    "                        else:\n",
    "                            data[col_target][i] = data[col_target].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_json('as24_cars.json')\n",
    "df = df0.copy()\n",
    "df.fillna('Unknown', inplace=True)\n",
    "def_col_name(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvgJ5KWTs1MB"
   },
   "source": [
    "# PART- 1 `( Data Cleaning )`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kodun çalışma süresi: 172.18 saniye\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 1. Column READY\n",
    "for i in range(len(df.make_model)):\n",
    "    selected = df.make_model[i].split()[1:]\n",
    "    df['make_model'][i] = ' '.join(selected)\n",
    "\n",
    "# 2. Column UNREADY\n",
    "# df.short_description.sample(10)\n",
    "\n",
    "# 3. Column READY\n",
    "for i in range(len(df.make)):\n",
    "    df['make'][i] = df.make[i].strip()\n",
    "\n",
    "# 4. Column READY\n",
    "def_clean_column(df.model)  \n",
    "\n",
    "# 5. Column READY\n",
    "for i in range(len(df.location)):\n",
    "    if df.location[i] != 'Unknown':\n",
    "        df.location[i] = df.location[i].split()[-1]\n",
    "        \n",
    "# 6. Column READY\n",
    "for i in range(len(df.price)):\n",
    "    df.price[i] = df.price[i].replace('€','').replace(',','').replace('.-','').strip()\n",
    "df.price.replace('Unknown',np.nan, inplace=True)\n",
    "df.price = df.price.astype('float')\n",
    "\n",
    "# 7. Column READY\n",
    "def_clean_column(df.body_type)\n",
    "\n",
    "# 8. Column READY\n",
    "\n",
    "def_clean_column(df.type)\n",
    "\n",
    "# 9. Column READY\n",
    "def_clean_column(df.doors)\n",
    "df.doors.replace('Unknown',np.nan, inplace=True)\n",
    "df.doors = df.doors.astype('float')\n",
    "\n",
    "# 10. Column READY\n",
    "def_clean_column(df.country_version)\n",
    "\n",
    "# 11. Column READY\n",
    "def_clean_column(df.offer_number)\n",
    "\n",
    "# 12. Column READY\n",
    "def_clean_column(df.warranty)\n",
    "\n",
    "# 13. Column READY\n",
    "for i in range(len(df.mileage)):\n",
    "    df.mileage[i] = df.mileage[i].strip().replace(',','').replace('km','')\n",
    "df.mileage.replace('Unknown',np.nan, inplace=True)\n",
    "df.mileage = df.mileage.astype('float')\n",
    "\n",
    "# 14. Column READY\n",
    "df.first_registration.replace('Unknown', np.nan, inplace=True)\n",
    "df.first_registration = pd.to_datetime(df.first_registration, format='%m/%Y')\n",
    "\n",
    "# 15. Column READY\n",
    "def_clean_column1(df.gearbox)\n",
    "\n",
    "# 16. Column UNREADY\n",
    "# df.fuel_type.value_counts()\n",
    "\n",
    "# 17. Column READY\n",
    "# df.colour.value_counts()\n",
    "\n",
    "# 18. Column READY\n",
    "# df.paint.value_counts()\n",
    "\n",
    "# 19. Column UNREADY\n",
    "for i in range(len(df.desc)):\n",
    "    if type(df.desc[i]) == list:\n",
    "        df.desc[i] = str(df.desc[i])\n",
    "        \n",
    "# 20. Column READY\n",
    "df.seller.value_counts()\n",
    "\n",
    "# 21. Column READY\n",
    "def_clean_column(df.seats)\n",
    "df.seats.replace('Unknown',np.nan, inplace=True)\n",
    "df.seats = df.seats.astype('float')\n",
    "\n",
    "# 22. Column READY\n",
    "df['power_kw'] = pd.Series([None]*len(df))\n",
    "df['power_hp'] = pd.Series([None]*len(df))\n",
    "for i in range(len(df.power)):\n",
    "    if df.power[i] != 'Unknown':\n",
    "        df['power_kw'][i] = re.findall(r'\\d+', df.power[i][0].strip())[0]\n",
    "        df['power_hp'][i] = re.findall(r'\\d+', df.power[i][0].strip())[1]\n",
    "df.drop('power', axis=1, inplace=True)\n",
    "\n",
    "# 23. Column READY\n",
    "for i in range(len(df.engine_size)):\n",
    "    if df.engine_size[i] != 'Unknown':\n",
    "        df.engine_size[i] = df.engine_size[i][0].strip().replace(',','').rstrip('cc').strip()\n",
    "df.engine_size.replace('Unknown',np.nan, inplace=True)\n",
    "df.engine_size = df.engine_size.astype('float')\n",
    "\n",
    "# 24. Column READY\n",
    "def_clean_column1(df.gears)\n",
    "df.gears.replace('Unknown',np.nan, inplace=True)\n",
    "df.gears = df.gears.astype('float')\n",
    "\n",
    "# 25. Column READY\n",
    "for i in range(len(df.co2_emissions)):\n",
    "    if df.co2_emissions[i] != 'Unknown':\n",
    "        df.co2_emissions[i] = df.co2_emissions[i].replace('g/km (comb.)','').replace(',','').strip()\n",
    "df.co2_emissions.replace('Unknown',np.nan, inplace=True)\n",
    "df.co2_emissions = df.co2_emissions.astype('float')\n",
    "\n",
    "# 26. Column UNREADY\n",
    "# df.manufacturer_colour.value_counts()\n",
    "\n",
    "# 27. Column READY\n",
    "def_clean_column(df.drivetrain)\n",
    "\n",
    "# 28. Column READY\n",
    "def_clean_column1(df.cylinders)\n",
    "df.cylinders.replace('Unknown',np.nan, inplace=True)\n",
    "df.cylinders = df.cylinders.astype('float')\n",
    "\n",
    "# 29. Column READY\n",
    "df['consumption_comb'] = pd.Series([None]*len(df))\n",
    "df['consumption_city'] = pd.Series([None]*len(df))\n",
    "df['consumption_country'] = pd.Series([None]*len(df))\n",
    "\n",
    "for i in range(len(df.fuel_consumption)):\n",
    "    if df.fuel_consumption[i] != 'Unknown':\n",
    "        if len(df.fuel_consumption[i]) == 1:\n",
    "            assign_consumption_value(df, i, 0, df.fuel_consumption[i][0][0].split()[3])\n",
    "        elif len(df.fuel_consumption[i]) == 2:\n",
    "            assign_consumption_value(df, i, 0, df.fuel_consumption[i][0][0].split()[3])\n",
    "            assign_consumption_value(df, i, 1, df.fuel_consumption[i][1][0].split()[3])\n",
    "        elif len(df.fuel_consumption[i]) == 3:\n",
    "            assign_consumption_value(df, i, 0, df.fuel_consumption[i][0][0].split()[3])\n",
    "            assign_consumption_value(df, i, 1, df.fuel_consumption[i][1][0].split()[3])\n",
    "            assign_consumption_value(df, i, 2, df.fuel_consumption[i][2][0].split()[3])\n",
    "df.consumption_city = df.consumption_city.astype('float')\n",
    "df.consumption_comb = df.consumption_comb.astype('float')\n",
    "df.consumption_country = df.consumption_country.astype('float')\n",
    "df.drop('fuel_consumption', axis=1, inplace=True)\n",
    "\n",
    "# 30. Column READY\n",
    "for i in range(len(df.comfort_convenience)):\n",
    "    if df.comfort_convenience[i] != 'Unknown':\n",
    "        df.comfort_convenience[i] = df.comfort_convenience[i][0]\n",
    "        \n",
    "# 31. Column READY\n",
    "for i in range(len(df.entertainment_media)):\n",
    "    if df.entertainment_media[i] != 'Unknown':\n",
    "        df.entertainment_media[i] = df.entertainment_media[i][0]\n",
    "\n",
    "# 32. Column READY\n",
    "for i in range(len(df.safety_security)):\n",
    "    if df.safety_security[i] != 'Unknown':\n",
    "        df.safety_security[i] = df.safety_security[i][0]\n",
    "        \n",
    "# 33. Column READY\n",
    "for i in range(len(df.extras)):\n",
    "    if df.extras[i] != 'Unknown':\n",
    "        df.extras[i] = df.extras[i][0]\n",
    "        \n",
    "# 34. Column READY\n",
    "for i in range(len(df.empty_weight)):\n",
    "    if df.empty_weight[i] != 'Unknown':\n",
    "        df.empty_weight[i] = df.empty_weight[i][0].replace(',','').replace('kg','').strip()\n",
    "df.empty_weight.replace('Unknown',np.nan, inplace=True)\n",
    "df.empty_weight = df.empty_weight.astype('float')\n",
    "\n",
    "# 35. Column READY\n",
    "def_clean_column(df.model_code)\n",
    "\n",
    "# 36. Column READY\n",
    "# print(df.general_inspection.sample(20))\n",
    "\n",
    "# 37. Column READY\n",
    "# print(df.last_service.sample(20))\n",
    "\n",
    "# 38. Column READY\n",
    "# print(df.full_service_history.sample(20))\n",
    "\n",
    "# 39. Column READY\n",
    "# df.non_smoker_vehicle.value_counts()\n",
    "\n",
    "# 40. Column READY\n",
    "# df.emission_class.value_counts()\n",
    "\n",
    "# 41. Column READY\n",
    "# df.emissions_sticker.value_counts()\n",
    "\n",
    "# 42. Column READY\n",
    "# df.upholstery_colour.value_counts()\n",
    "\n",
    "# 43. Column READY\n",
    "# df.upholstery.value_counts()\n",
    "\n",
    "# 44. Column READY\n",
    "# df.production_date.value_counts()\n",
    "\n",
    "# 45. Column READY\n",
    "df['preown_km'] = pd.Series([None]*len(df))\n",
    "df['preown_date'] = pd.Series([None]*len(df))\n",
    "df['preown_num'] = pd.Series([None]*len(df))\n",
    "\n",
    "for i in range(len(df.previous_owner)):\n",
    "    if df.previous_owner[i] != 'Unknown':\n",
    "        df.preown_km[i] = df.previous_owner[i][0][0].replace(',','').replace('km','').strip()\n",
    "        df.preown_date[i] = df.previous_owner[i][0][1]\n",
    "        df.preown_num[i] = df.previous_owner[i][1]\n",
    "df.drop('previous_owner', axis=1, inplace=True)\n",
    "\n",
    "# 46. Column READY\n",
    "# df.other_fuel_types.value_counts()\n",
    "\n",
    "# 47. Column READY\n",
    "# df.power_consumption.value_counts()\n",
    "\n",
    "# 48. Column UNREADY\n",
    "# df.energy_efficiency_class.value_counts()\n",
    "\n",
    "# 49. Column READY\n",
    "# df.co2_efficiency.value_counts()\n",
    "\n",
    "# 50. Column READY\n",
    "# df.fuel_consumption_wltp.value_counts()\n",
    "\n",
    "# 51. Column READY\n",
    "# df.co2_emissions_wltp.value_counts()\n",
    "\n",
    "# 52. Column READY\n",
    "\n",
    "for i in range(len(df['available_from'])):\n",
    "    if df['available_from'][i] != 'Unknown':\n",
    "        df['available_from'][i] = df['available_from'][i][0].replace(',','').strip()\n",
    "df.available_from.replace('Unknown', np.nan, inplace=True)\n",
    "df.available_from = pd.to_datetime(df.available_from, format='%d/%m/%Y')\n",
    "\n",
    "# 53. Column READY\n",
    "# df.taxi_or_rental_car.value_counts()\n",
    "\n",
    "# 54. Column READY\n",
    "for i in range(len(df.availability)):\n",
    "    if df.availability[i] != 'Unknown':\n",
    "        df.availability[i] = df.availability[i][0].split()[2]\n",
    "df.availability.replace('Unknown',np.nan, inplace=True)\n",
    "df.availability = df.availability.astype('float')\n",
    "\n",
    "# 55. Column READY\n",
    "# df.last_timing_belt_change.value_counts()\n",
    "\n",
    "# 56. Column READY\n",
    "# df.electric_range_wltp.value_counts()\n",
    "\n",
    "# 57. Column READY\n",
    "# df.power_consumption_wltp.value_counts()\n",
    "\n",
    "# 58. Column READY\n",
    "# df.battery_ownership.value_counts()\n",
    "\n",
    "# ADDITIONAL\n",
    "df['fuel_type'] = df['fuel_type'].transform(lambda x: 'Benzine' if re.search('Gasoline', x) else 'Benzine' if re.search('Super', x) else 'Benzine' if re.search('Benzine', x) else 'Benzine' if re.search('Others', x) else 'LPG' if re.search('CNG', x) else 'LPG' if re.search('LPG', x) else 'LPG' if re.search('gas', x) else 'Electric' if re.search('Electric', x) else 'LPG' if re.search('Ethanol', x) else 'LPG' if re.search('Biogas', x) else 'Diesel' if re.search('Diesel', x) else 'Diesel')\n",
    "for i in range(len(df)):\n",
    "    if df.iloc[i]['other_fuel_types'] == 'Electricity':\n",
    "        df['fuel_type'].iloc[i] = 'Electric'\n",
    "\n",
    "df.power_hp = df.power_hp.astype('float')\n",
    "df.power_kw = df.power_kw.astype('float')\n",
    "        \n",
    "\n",
    "df.replace('Unknown', np.nan, inplace=True)\n",
    "df.drop_duplicates(keep='first', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.drop(1775, axis=0, inplace=True)\n",
    "\n",
    "for i in df[(df.model == '') & (df.make=='Opel')].index:\n",
    "    a = df.short_description[i].split()[0]\n",
    "    if len(re.findall('\\d', a)) > 0:\n",
    "        pass\n",
    "    else:\n",
    "        df.model[i] = a\n",
    "for i in df[df.model == ''].index:\n",
    "    df.model[i] = np.nan\n",
    "for i in df[(df.consumption_city.isnull() == False) & (df.consumption_country.isnull() == False) & (df.consumption_comb.isnull() == True)].index:\n",
    "    df.consumption_comb[i] = (df.consumption_city[i] + df.consumption_country[i])/2\n",
    "    \n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Kodun çalışma süresi: {:.2f} saniye\".format(end - start))\n",
    "# Kodun çalışma süresi: 157.99 saniye\n",
    "# Kodun çalışma süresi: 204.40 saniye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('df_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGeKSdYds1MD"
   },
   "source": [
    "# PART- 2 `( Handling With Missing Vales )`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kodun çalışma süresi: 430.93 saniye\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "def_fill_miss(df, 1, 'mode', 'doors', 'body_type')\n",
    "\n",
    "def_fill_miss(df, 1, 'mean', 'first_registration', 'model')\n",
    "df.first_registration = df.first_registration.transform(lambda x: x.year)\n",
    "\n",
    "def_fill_miss(df, 3, 'mode', 'model', 'make', 'first_registration', 'body_type')\n",
    "\n",
    "def_fill_miss(df, 2, 'mean', 'mileage', 'model', 'first_registration')\n",
    "\n",
    "def_fill_miss(df, 2, 'mode', 'gearbox', 'model', 'first_registration')\n",
    "\n",
    "def_fill_miss(df, 2, 'mode', 'seats', 'model', 'body_type')\n",
    "\n",
    "def_fill_miss(df, 2, 'mode', 'cylinders', 'make', 'model', 'first_registration')\n",
    "\n",
    "def_fill_miss(df, 3, 'mode', 'engine_size', 'cylinders', 'first_registration', 'fuel_type')\n",
    "\n",
    "def_fill_miss(df, 2, 'mode', 'gears', 'model', 'first_registration')\n",
    "\n",
    "def_fill_miss(df, 2, 'mode', 'drivetrain', 'model', 'first_registration')\n",
    "\n",
    "def_fill_miss(df, 2, 'mode', 'comfort_convenience', 'first_registration', 'model')\n",
    "\n",
    "def_fill_miss(df, 2, 'mode', 'entertainment_media', 'first_registration', 'model')\n",
    "\n",
    "def_fill_miss(df, 2, 'mode', 'safety_security', 'first_registration', 'model')\n",
    "\n",
    "def_fill_miss(df, 2, 'mode', 'extras', 'model', 'first_registration')\n",
    "\n",
    "def_fill_miss(df, 3, 'mode', 'empty_weight', 'model', 'first_registration', 'body_type')\n",
    "\n",
    "def_fill_miss(df, 2, 'mode', 'colour', 'model', 'body_type')\n",
    "\n",
    "def_fill_miss(df, 3, 'mode', 'emission_class', 'model', 'engine_size', 'body_type')\n",
    "\n",
    "def_fill_miss(df, 3, 'mean', 'consumption_comb', 'make', 'first_registration', 'cylinders')\n",
    "\n",
    "def_fill_miss(df, 3, 'mode', 'upholstery','make', 'first_registration', 'body_type')\n",
    "\n",
    "def_fill_miss(df, 3, 'mean', 'power_hp', 'model', 'engine_size', 'first_registration')\n",
    "\n",
    "def_fill_miss(df, 3, 'mean', 'power_kw', 'model', 'engine_size', 'first_registration')\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\nKodun çalışma süresi: {:.2f} saniye\".format(end - start))\n",
    "\n",
    "# Kodun çalışma süresi: 603.73 saniye\n",
    "# Kodun çalışma süresi: 469.59 saniye\n",
    "# Kodun çalışma süresi: 426.79 saniye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_miss = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_miss.to_csv('df_miss.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPPdPAu5s1ME"
   },
   "source": [
    "# PART- 3 `( Handling With Outliers )`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.seats <= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.first_registration <= 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.gears >= 4) & (df.gears <=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.cylinders >= 2) & (df.cylinders <= 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df[(df.engine_size >= 800) & (df.cylinders <= 6000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.empty_weight >= 700) & (df.empty_weight <= 25000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKxmsgfts1MG"
   },
   "source": [
    "# Final Step (Checking final situation of data via graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "8mgL_Bd0s1MG"
   },
   "outputs": [],
   "source": [
    "df.dropna(axis=1, inplace=True)\n",
    "df.drop_duplicates(keep='first', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('df_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PgUVPoes1MH"
   },
   "source": [
    "## Export dataframe to csv file (without dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    if df.first_registration[i] > 2017:\n",
    "        df.model[i] = 'New'\n",
    "    else:\n",
    "        df.model[i] = 'Old'\n",
    "        \n",
    "for i in range(len(df)):\n",
    "    if df.colour[i] in ['Black', 'Grey', 'Silver', 'Bronze', 'Brown']:\n",
    "        df.colour[i] = 'Dark'\n",
    "    elif df.colour[i] in ['Yellow', 'White', 'Beige','Gold']:\n",
    "        df.colour[i] = 'Light'\n",
    "    else:\n",
    "        df.colour[i] = 'Others' \n",
    "        \n",
    "for i in range(len(df)):\n",
    "    if df.seller[i] != 'Dealer':\n",
    "        df.seller[i] = 'Private_Seller'        \n",
    "        \n",
    "for i in range(len(df)):\n",
    "    df.comfort_convenience[i] = len(df.comfort_convenience[i].split(','))        \n",
    "        \n",
    "for i in range(len(df)):\n",
    "    df.entertainment_media[i] = len(df.entertainment_media[i].split(','))        \n",
    "        \n",
    "for i in range(len(df)):\n",
    "    df.safety_security[i] = len(df.safety_security[i].split(','))        \n",
    "        \n",
    "for i in range(len(df)):\n",
    "    df.extras[i] = len(df.extras[i].split(','))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.first_registration = df.first_registration.transform(lambda x: 2023-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep='first', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('short_description', axis=1, inplace=True)\n",
    "df.drop('make_model', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.comfort_convenience = df.comfort_convenience.astype('int')\n",
    "df.entertainment_media = df.entertainment_media.astype('int')\n",
    "df.safety_security = df.safety_security.astype('int')\n",
    "df.extras = df.extras.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep='first', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Byg_o2ZMs1MI"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"final_scout_not_dummy.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrw9hr-3s1MJ"
   },
   "source": [
    "# Dummy Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUOdihlqs1MJ"
   },
   "source": [
    "## Export dataframe to csv file (dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummied = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "IJT7Yl1Us1MK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dummied.to_csv(\"final_scout_dummy.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "DAwPy-Capstone_Project_(AutoScout)_Student.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
